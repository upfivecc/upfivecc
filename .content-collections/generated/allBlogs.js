
export default [
  {
    "content": "# 大模型MCP介绍\n\n随着人工智能和大规模语言模型（Large Language Models，LLM）技术的飞速发展，如何高效、安全、准确地管理和传递模型上下文信息，成为提升模型性能和用户体验的关键。**模型上下文协议（Model Context Protocol，简称 MCP）**应运而生，作为大模型交互中管理上下文信息的技术规范和实践框架，在业界逐渐得到关注和应用。  \n\n本文将从 MCP 的定义、原理、关键技术、应用场景、优势与挑战、未来发展等角度，系统介绍模型上下文协议的核心内容，帮助读者全面理解这一大模型生态中的重要组成部分。\n\n---\n\n## 目录\n\n- [一、什么是模型上下文协议（MCP）](#一什么是模型上下文协议mcp)\n- [二、MCP 在大模型中的作用和意义](#二mcp-在大模型中的作用和意义)\n- [三、模型上下文协议的核心原理](#三模型上下文协议的核心原理)\n- [四、MCP 的关键技术组成](#四mcp-的关键技术组成)\n- [五、MCP 的应用场景](#五mcp-的应用场景)\n- [六、MCP 的优势与面临的挑战](#六mcp-的优势与面临的挑战)\n- [七、未来 MCP 发展趋势](#七未来-mcp-发展趋势)\n- [八、总结](#八总结)\n\n---\n\n## 一、什么是模型上下文协议（MCP）\n\n模型上下文协议（Model Context Protocol，MCP）是一套定义大规模语言模型在推理、交互过程中如何管理和传递上下文信息的技术标准和协议规范。  \n\n简单来说，MCP 旨在解决大模型“上下文信息传递”的规范化问题，使得模型能够：\n\n- 有效地接收和处理用户输入的历史信息；\n- 在多轮对话、复杂任务中保持上下文连贯性；\n- 实现多模型、多系统间上下文信息的共享和协同。\n\n通过 MCP，模型及其调用系统能够形成一套统一且高效的上下文管理机制，保障对话流畅、内容准确和系统兼容。\n\n---\n\n## 二、MCP 在大模型中的作用和意义\n\n### 1. 保障上下文连贯性\n\n大模型在处理多轮对话或长文本生成时，必须依赖上下文信息，否则容易出现前后矛盾、遗忘先前信息等问题。MCP 规范了上下文数据的结构和传输方式，使模型能准确理解用户意图和历史内容。\n\n### 2. 实现跨平台多模型协作\n\n当前许多 AI 应用场景涉及多个大模型协同工作，MCP 提供统一协议支持跨模型、跨平台的上下文共享，提升整体智能系统的协调效率。\n\n### 3. 降低系统集成复杂度\n\n通过明确上下文协议规范，开发者可以更简单地集成不同模型与服务，减少上下文管理的二次开发和维护成本。\n\n### 4. 提升隐私和安全保障\n\nMCP 可设计为包含上下文权限管理和隐私保护策略，避免上下文泄露和敏感信息滥用，增强用户信任。\n\n---\n\n## 三、模型上下文协议的核心原理\n\n### 1. 上下文数据结构化\n\nMCP 通过标准化上下文信息的数据结构（如 JSON、Protobuf 等），定义包含对话历史、用户意图、实体信息、元数据等内容的统一格式，方便模型解析和处理。\n\n### 2. 上下文窗口管理\n\n由于大模型输入长度有限，MCP 明确上下文截断和窗口滑动机制，保证重点信息优先传递，同时支持动态扩展上下文长度。\n\n### 3. 多轮对话状态同步\n\nMCP 规定如何标识对话轮次、回复来源和上下文链路，实现对话状态的持续跟踪与同步，避免对话“断线”。\n\n### 4. 版本与兼容性控制\n\n协议设计考虑版本迭代，确保不同版本模型和调用端之间的上下文兼容，支持平滑升级和回滚。\n\n### 5. 加密与访问控制\n\n上下文协议中包含加密规范和访问权限标识，防止未授权访问和数据篡改，保障上下文安全。\n\n---\n\n## 四、MCP 的关键技术组成\n\n| 组成部分       | 说明                                                         |\n| -------------- | ------------------------------------------------------------ |\n| **上下文格式** | 统一的数据格式标准，支持灵活扩展，如 JSON Schema 或 Protobuf，确保数据结构清晰且易解析。 |\n| **上下文管理** | 定义上下文生命周期，包括创建、更新、合并、裁剪和删除等操作。   |\n| **多轮对话标识** | 对话 ID、轮次编号、发言角色（用户/模型/系统）标识，保证对话连续性。 |\n| **元数据扩展** | 支持注入用户偏好、意图标签、情感分析结果等辅助信息。             |\n| **传输协议**   | 支持 HTTP/HTTPS、WebSocket 等多种传输方式，兼顾实时性和安全性。 |\n| **安全策略**   | 加密机制、访问控制列表（ACL）、身份认证和审计日志。             |\n\n---\n\n## 五、MCP 的应用场景\n\n### 1. 智能客服系统\n\n通过 MCP 管理用户多轮对话历史，实现问题上下文理解，精准回答，提升客户体验。\n\n### 2. 个人助理与聊天机器人\n\n保证助理对用户偏好、历史指令的持续记忆，实现更自然流畅的人机交互。\n\n### 3. 跨模型融合应用\n\n如文本-图像多模态生成、多模型知识补全等，MCP 协议保障不同模型间上下文信息传递顺畅。\n\n### 4. 企业知识管理\n\n集成大模型进行文档检索与生成，MCP 规范上下文存储与更新，实现信息准确调取。\n\n### 5. 语音识别与合成\n\n上下文协议用于语音转文本后续处理，保证语音交互连贯性和上下文相关性。\n\n---\n\n## 六、MCP 的优势与面临的挑战\n\n### 优势\n\n- **规范化管理**：统一上下文格式和传输方式，降低集成门槛。\n- **提升用户体验**：保障对话连续性和语义一致性。\n- **支持多模型协作**：实现复杂 AI 系统的协同。\n- **安全合规**：内置隐私保护和访问控制机制。\n- **易扩展**：支持多模态、多任务上下文融合。\n\n### 挑战\n\n- **上下文容量限制**：大模型输入限制使长上下文管理复杂，需智能裁剪。\n- **隐私与安全风险**：上下文包含敏感信息，保护难度大。\n- **多方兼容性**：不同模型、平台的协议统一难度高。\n- **实时性需求**：上下文传输需低延迟保证交互体验。\n- **标准化进展缓慢**：业界尚无统一成熟标准，协议多样化。\n\n---\n\n## 七、未来 MCP 发展趋势\n\n### 1. 标准化与开源\n\n业界将推动 MCP 标准的统一和开源，形成广泛共识与生态支持。\n\n### 2. 智能上下文管理\n\n结合知识图谱、记忆网络实现智能上下文压缩、召回和动态调整。\n\n### 3. 跨模态上下文融合\n\n支持文本、图像、音频等多模态上下文统一管理。\n\n### 4. 隐私计算集成\n\n结合联邦学习、同态加密技术，实现安全隐私的上下文共享。\n\n### 5. 边缘计算支持\n\n推动 MCP 在边缘设备的轻量化，实现本地上下文存储与管理。\n\n---\n\n## 八、总结\n\n模型上下文协议（MCP）作为大模型技术生态中的关键组成，承载着保障多轮对话连贯性、多模型协同工作和上下文安全管理的重任。随着大模型应用场景的丰富和复杂化，MCP 的规范化、智能化发展将成为推动 AI 行业迈向更高阶段的重要推动力。\n\n深入理解并应用 MCP，将助力 AI 开发者和企业打造更强大、更安全、更高效的智能系统，实现人机交互的自然流畅和业务价值的最大化。\n\n---\n\n如果你对 MCP 或大模型上下文管理有兴趣，欢迎交流讨论，一起探索前沿技术与创新实践！",
    "title": "大模型 MCP 介绍",
    "date": "2025-03-05T21:10:00+08:00",
    "updated": "2025-03-05T21:10:00+08:00",
    "featured": true,
    "summary": "大模型 MCP 介绍",
    "keywords": [
      "独立开发",
      "大模型",
      "MCP"
    ],
    "_meta": {
      "filePath": "ai-mcp-intro.md",
      "fileName": "ai-mcp-intro.md",
      "directory": ".",
      "extension": "md",
      "path": "ai-mcp-intro"
    },
    "slug": "ai-mcp-intro"
  },
  {
    "content": "## 前言\n\n其实一直有很多人问我，Prompt要怎么写效果才好，有没有模板。\n\n我每次都会说，能清晰的表达你的想法，才是最重要的，各种技巧都是其次。但是，我还是希望发给他们一些靠谱的文档。\n\n但是，网上各种所谓的Prompt框架、教程，真的乱七八糟，让人头都大。\n\n直到前两天，12月15号，OpenAI在他们的文档里上线了Prompt engineering，也就是提示词工程指南，至此，终于算是有了一个权威且有效的Prompt工程标准文档。\n\n我花了20分钟看完了后，其实挺会心一笑的，整篇指南简洁、明确、高效，写的非常棒。\n\nOpenAI提到6条大的原则，分别是：\n\n1. Write clear instructions（写出清晰的指令）\n\n2. Provide reference text（提供参考文本）\n\n3. Split complex tasks into simpler subtasks（将复杂的任务拆分为更简单的子任务）\n\n4. Give the model time to \"think\"（给模型时间“思考”）\n\n5. Use external tools（使用外部工具）\n\n6. Test changes systematically（系统地测试变更）\n\n我用这篇文章，来通俗易懂的给大家聊一下具体的原则和例子，第六条可以不看，对普通用户没啥大用。最后我会再放一张脑图，没空看的可以收藏一下文章，然后滑到最后去保存脑图。\n\n我觉得可以信我，市面上99%的Prompt框架和技巧，都不如这一篇文章有用。\n\n## 一. 写出清晰的指令\n\n这个其实就是我天天说的，任何Prompt技巧都不如清晰的表达你的需求，这就像人与人沟通一样，话都说不明白，怎么能让对面理解你呢？一味的靠抄Prompt模板，其实不是长久之计。\n\n所以，写出清晰的指令，是核心中的核心。\n\n如何写出清晰的指令，OpenAI给出了6条小技巧：\n\n\n### 1. 把话说详细\n\n尽量多的提供任何重要的详细信息和上下文，说白了，就是把话说明白一点，不要一个太笼统。\n\n比如：不要说：“总结会议记录”\n而是说：“用一个段落总结会议记录。然后写下演讲者的 Markdown 列表以及他们的每个要点。最后，列出发言人建议的后续步骤或行动项目（如果有）。”\n\n### 2. 让模型充当某个角色\n\n你可以把大模型想象成一个演员，你要告诉他让他演什么角色，他就会更专业更明确，一个道理。\n\n比如：充当一个喜欢讲笑话的喜剧演员，每当我当我请求帮助写一些东西时，你会回复一份文档，其中每个段落至少包含一个笑话或有趣的评论。\n\n### 3. 使用分隔符清楚地指示输入的不同部分\n\n三引号、XML 标签、节标题等分隔符可以帮助划分要区别对待的文本节。可以帮助大模型更好的理解文本内容。我最喜欢用\"\"\"把内容框起来。\n\n比如：用50个字符总结由三引号分隔的文本。在此插入文字\n\n### 4. 指定完成任务所需的步骤\n\n有些任务能拆就拆，最好指定为一系列步骤。明确地写出这些步骤可以使模型更容易去实现它们。\n\n比如：使用以下分步说明来响应用户输入。 \n步骤1 - 用户将为您提供三引号中的文本。用一个句子总结这段文字，并加上前缀“Summary:”。 \n步骤2 - 将步骤1中的摘要翻译成西班牙语，并添加前缀“翻译：”。\n\n### 5. 提供例子\n\n也就是经典的少样本提示，few-shot prompt，先扔给大模型例子，让大模型按你的例子来输出。\n\n比如：按这句话的风格来写XX文章：\"\"\"落霞与孤鹜齐飞，秋水共长天一色。渔舟唱晚，响穷彭蠡之滨\n\n### 6. 指定所输出长度\n\n可以要求模型生成给定目标长度的输出。目标输出长度可以根据单词、句子、段落、要点等的计数来指定。中文效果不明显，同时你给定的长度只是个大概，多少个字这种肯定会不精准，但是像多少段这种效果就比较好。\n\n比如：用两个段落、100个字符概括由三引号分隔的文本。在此插入文字\n\n\n## 二. 提供参考文本\n\n给大模型文本或者文档，能大幅度的降低大模型胡说八道的概率。其实就是把大模型当知识库来用。\n\n### 1. 让模型使用参考文本作答\n\n知识库的经典用法，让大模型使用我们提供的信息来组成其答案。\n\n比如：使用提供的由三重引号引起来的文章来回答问题。如果在文章中找不到答案，请写“我找不到答案”。\n\n问题：在此插入问题\n\n### 2. 让模型通过引用参考文本来回答\n\n如果已经给了文本，则可以直接要求模型通过引用所提供文档中的段落来为其答案添加引用。可以提高正确性，增加可验证性。\n\n比如：您将获得一份由三重引号和一个问题分隔的文档。您的任务是仅使用提供的文档回答问题，并引用用于回答问题的文档段落。如果文档不包含回答此问题所需的信息，则只需写：“信息不足”。如果提供了问题的答案，则必须附有引文注释。使用以下格式引用相关段落。\n\n\n## 三. 将复杂的任务拆分为更简单的子任务\n\n其实跟人类一样，你作为Leader，让下属一次性去做一个非常大的事，出错的概率是很大的，很多大项目也是这样，你甚至无从下手。所以经常我们在工作中，都说的是要拆，拆各种细节、子任务、子目标等等。大模型也是同样的道理。\n把复杂的任务给拆给更为简单的子任务，大模型会有更好的表现。\n\n### 1. 使用意图分类来识别与用户查询最相关的指令\n\n意图识别是一个很经典的例子。比如在客服场景中，用户问了一个问题“我断网了咋整”，你让大模型直接回复其实是挺蛋疼的，但是这时候就可以拆，先拆大分类下的意图识别，再回答具体的问题。\n比如还是“我断网了咋整”这个问题：\n步骤1，先判断问题类别：\n\n\n### 2. 对于需要很长对话的对话应用，总结或过滤之前的对话\n\n这个技巧偏开发者。普通用户可以跳过。\n因为模型具有固定的上下文长度，因此用户和助手之间的对话无法无限期地继续。\n解决此问题有多种解决方法，第一个是总结对话中的历史记录。一旦输入的大小达到预定的阈值长度，这可能会触发总结部分对话的查询，并且先前对话的摘要可以作为系统消息的一部分包括在内。或者，可以在整个对话过程中在后台异步总结之前的对话。\n这两种方法都行，或者还可以把过去的所有聊天记录存成向量库，后续跟用户对话的时候动态查询嵌入，也可以。\n\n### 3. 分段总结长文档并递归构建完整总结\n同样偏开发者。普通用户可以跳过。\n\n其实就是总结几百页PDF文档的原理，比如让大模型总结一本书，肯定是超Token上限了嘛，所以可以使用一系列查询来总结文档的每个部分。章节摘要可以连接和总结，生成摘要的摘要。这个过程可以递归地进行，直到总结整个文档。 OpenAI 在之前的研究中已经使用 GPT-3 的变体研究了这种总结书籍的过程的有效性。\n\n详细的可以看这篇文档：https://openai.com/research/summarizing-books\n\n\n## 四. 给模型时间“思考”\n\nthink step by step（一步步思考）这个神级提示词的源头。其实也就是链式思考（CoT），Chain-of-Thought Prompting，非常非常有用的一个策略。\n\n还是跟人一样，我直接问你12314992*177881等于多少你肯定也懵逼，但是我要是给你时间让你一步步计算，学过小学数学的我觉得都能算出来对吧。\n\nOpenAI在CoT的基础上，又详细给出了3个技巧：\n\n### 1. 让模型在急于得出结论之前找出自己的解决方案\n\n比如你扔个数学题给大模型，你让他判断对或者不对，你会发现结果很随机，一会对或者不对，但是如果你先让他自己做一遍，再去判断对与不对，结果就会准非常多了。\n\n比如你可以说：首先制定自己的问题解决方案。然后将你的解决方案与学生的解决方案进行比较，并评估学生的解决方案是否正确。在你自己完成问题之前，不要决定学生的解决方案是否正确。\n\n### 2. 使用内心独白来隐藏模型的推理过程\n非常有意思的一个技巧，你可能会问不是说一步一步思考把推理过程放出来效果会更好嘛。\n你说的对，但是这条技巧是面对开发者的，对于某些应用程序，大模型用于得出最终答案的推理过程不适合与用户共享。例如，在辅导应用程序中，我们可能希望鼓励学生得出自己的答案，但模型关于学生解决方案的推理过程可能会向学生揭示答案。\n所以就有了这么一个内心独白的技巧。内心独白的想法是让模型将原本对用户隐藏的部分输出放入结构化格式中，以便于解析它们。然后，在向用户呈现输出之前，将解析输出并且仅使部分输出可见。\n\n\n### 3. 询问模型在之前的过程中是否遗漏了什么内容\n\n这个技巧在长文本问答中常用，比如我们给了一个文档，要让大模型模型来列出与一个特定问题相关的信息。如果源文档很大，模型通常会过早停止并且无法列出所有相关信息。在这种情况下，通过使用后续的promtp让模型查找之前传递中错过的任何相关信息，通常可以获得更好的性能。\n\n比如我让他根据我的文档，给我列出这个问题在文档中的相关片段：“北京烤鸭到底好吃在哪”，然后让他用JSON格式输出\n\n\n在输出停止以后，我们可以再问一句：\n\n还有更多相关片段吗？注意不要重复摘录。还要确保相关片段包含解释它们所需的所有相关上下文 - 换句话说，不要提取缺少重要上下文的小片段。\n\n\n## 五. 使用外部工具\n\n大模型并不是万能的，很多东西吧，大模型的效果并没有那么好，比如数学、比如一些实时问题等等，所以需要一些外部工具来帮助处理。\n\n换句话说，如果第三方工具能稳定的获得结果，那其实并不需要大模型去做什么，或者只让大模型做一个答案组装类的工作就够了。\n\n### 1. 使用基于嵌入的搜索实现高效的知识检索\n\n绝大部分知识库的原理，检索增强生成 (RAG)，Retrieval Augmented Generation，比如我问如何评价马上要上映的电影《海王2》，你让大模型自己去答肯定就废了，它是静态的，根本不知道《海王2》要上映了，所以需要先去联网进行查询，查完以后把一堆资料灌回来，让大模型自己根据自己查到的这些资料进行回答。这是动态的信息。\n\n但是也有静态的知识库，就是用的向量匹配的方式，常见步骤：加载文件 -> 读取文本 -> 文本分割 -> 文本向量化 -> 问句向量化 -> 在文本向量中匹配出与问句向量最相似的top k个 -> 匹配出的文本作为上下文和问题一起添加到prompt中 -> 提交给大模型生成回答。\n\n就是这么玩的。\n\n### 2. 使用代码执行来进行更准确的计算或调用外部API\n\n都知道大模型自己的计算能力垃圾，所以OpenAI建议，如果遇到需要计算的东西，最好让大模型写一段计算的Python代码，毕竟Python最计算题很成熟了。\n\n比如：求以下多项式的所有实值根：\n```\n3*x**5 - 5*x**4 - 3*x**3 - 7*x - 10。您需要通过将 Python 代码括在三个反引号中来编写和执行，\n例如\"\"\"代码放在这里\"\"\"。用它来执行计算。\n```\n\n当然，都用Python了，你也可以把自己的API文档复制给它，让大模型知道该如何写代码调用你的API。\n\n### 3. 给模型提供特定的功能\n\n很偏开发者的一个技巧，普通用户可以直接跳过。\n\n简而言之，你可以通过 API 请求，传递一系列特定的函数描述。告诉模型哪些函数是可用的，以及这些函数的参数应该是什么样的。然后模型模可以生成相应的函数参数，这些参数随后会以 JSON 格式通过 API 返回。\n\n你都拿到JSON数组了，跟数据库可以做多少交互相信也不用我多说了吧，做数据查询、数据处理等等，啥玩意都行。\n\n处理完以后再返回一个JSON数组给大模型，让大模型变成人类语言输出给用户，完事。\n\n## 六. 系统地测试变更\n\n可以直接跳过此节，对于普通用户几乎没用。\n\n主要是帮助开发者判断更改Prompt（例如新指令或新设计）是否使系统变得更好或更差。毕竟大部分时间的样本量都比较小，很难区分真正有改进还是纯粹的运气。\n\n所以，OpenAI建议搞个评估程序，用来判断优化系统的设计是否有效。\n\n这块我就不细说了，有兴趣的或者正在开发自己的AI应用的，可以自己去看看：\n\n\n## Reference\n\nhttps://openai.com/research/summarizing-books\n\nhttps://platform.openai.com/docs/guides/prompt-engineering/guide\n\nhttps://platform.openai.com/docs/guides/prompt-engineering/strategy-test-changes-systematically",
    "title": "OpenAI官方提示词教程",
    "date": "2024-03-05T21:10:00+08:00",
    "updated": "2024-03-05T21:10:00+08:00",
    "featured": true,
    "summary": "OpenAI官方提示词教程",
    "keywords": [
      "独立开发",
      "大模型",
      "提示词"
    ],
    "_meta": {
      "filePath": "ai-prompt-openai.md",
      "fileName": "ai-prompt-openai.md",
      "directory": ".",
      "extension": "md",
      "path": "ai-prompt-openai"
    },
    "slug": "ai-prompt-openai"
  },
  {
    "content": "这篇文章包含markdown语法基本的内容。\n\n在markdown里可以使用 \\ 对特殊符号进行转义。  \n\n# 1. 标题\n\n**语法**\n```md\n# This is an <h1> tag\n## This is an <h2> tag\n### This is an <h3> tag\n#### This is an <h4> tag\n```\n\n**实例**\n\n# This is an h1 tag\n## This is an h2 tag\n### This is an h3 tag\n#### This is an h4 tag\n\n# 2. 强调和斜体\n\n**语法**\n```md\n*This text will be italic*\n_This will also be italic_\n\n**This text will be bold**\n__This will also be bold__\n```\n\n**实例**\n\n*This text will be italic*\n_This will also be italic_\n\n**This text will be bold**\n__This will also be bold__\n\n# 3. 有序列表和无序列表\n\n**语法**\n```md\n* Item 1\n* Item 2\n* Item 3\n\n1. Item 1\n2. Item 2\n3. Item 3\n```\n\n**实例**\n* Item 1\n* Item 2\n* Item 3\n\n1. Item 1\n2. Item 2\n3. Item 3\n\n# 4. 图片\n\n**语法**\n```\n![img-name](img-url)\n```\n\n**实例**\n![微信公众号](https://storage.guangzhengli.com/images/wechat-official-account.png)\n\n# 5. 超链接\n\n**语法**\n```\n[link-name](link-url)\n```\n\n**实例**\n\n[微信公众号链接](https://storage.guangzhengli.com/images/wechat-official-account.png)\n\n# 6. 引用\n\n**语法**\n```md\n> 引用本意是引用别人的话之类  \n```\n\n**实例**\n\n> If you please draw me a sheep!  \n> 不想当将军的士兵, 不是好士兵.  \n\n# 7. 单行代码\n\n**语法**\n```\n`This is an inline code.`\n```\n\n**实例**\n\n`同样的单行代码, 我经常用来显示特殊名词`\n\n# 8. 多行代码\n\n**语法**\n\n```md\n​```js\nfor (var i=0; i<100; i++) {\n    console.log(\"hello world\" + i);\n}\n​```\n```\n\n**实例**\n\n```js\nfor (var i=0; i<100; i++) {\n    console.log(\"hello world\" + i);\n}\n```\n\n也可以通过缩进来显示代码, 下面是示例:  \n\n    console.loe(\"Hello_World\");\n\n# 9. 表格\n\n## Table\n\n| Table Header 1 | Table Header 2 | Table Header 3 |\n| - | - | - |\n| Division 1 | Division 2 | Division 3 |\n| Division 1 | Division 2 | Division 3 |\n| Division 1 | Division 2 | Division 3 |\n\n# 参考链接\n\n- https://guides.github.com/features/mastering-markdown/  \n- https://help.github.com/articles/basic-writing-and-formatting-syntax/",
    "title": "Markdown 基本用法",
    "date": "2022-04-05T20:10:00+08:00",
    "updated": "2022-04-05T20:10:00+08:00",
    "featured": true,
    "summary": "这篇文章包含markdown语法基本的内容。",
    "keywords": [
      "hello",
      "world"
    ],
    "_meta": {
      "filePath": "hello-world.md",
      "fileName": "hello-world.md",
      "directory": ".",
      "extension": "md",
      "path": "hello-world"
    },
    "slug": "hello-world"
  },
  {
    "content": "这是一个 Nextjs 博客模板，本文会介绍这个模板的一些基本用法。\n\n## 1. 如何编写博客\n\n这个仓库的博客文件需要放在 `src/content/blog` 目录下，可以是 markdown 文件，也可以是 mdx 文件。\n\n有以下这些元数据需要用户自行根据需要进行配置：\n\n- `title`: 博客标题\n- `date`: 博客发布日期\n- `updated`: 博客更新日期\n- `keywords`: 博客关键词，优化 SEO\n- `featured`: 是否放在首页\n- `summary`: 博客摘要\n\n## 2. 博客配置\n\n博客的所有配置都集中在 `src/lib/config.ts` 文件中，这样做的好处是：\n\n1. 集中管理：所有配置都在一个文件中，方便维护和修改\n2. 类型安全：使用 TypeScript 可以获得类型检查和自动补全\n3. 复用性：避免重复的配置散落在各个文件中\n4. 一致性：确保所有地方使用相同的配置值\n\n### 2.1 站点基本配置\n\n```typescript\nsite: {\n  title: \"你的博客标题\",\n  name: \"你的博客名称\",\n  description: \"博客描述\",\n  keywords: [\"关键词1\", \"关键词2\"],\n  url: \"https://你的域名.com\",\n  baseUrl: \"https://你的域名.com\",\n  image: \"https://你的域名.com/og-image.png\",\n  favicon: {\n    ico: \"/favicon.ico\",\n    png: \"/favicon.png\",\n    svg: \"/favicon.svg\",\n    appleTouchIcon: \"/favicon.png\",\n  },\n  manifest: \"/site.webmanifest\",\n}\n```\n\n这些配置用于：\n- 网站的基本信息展示\n- SEO 优化\n- 浏览器标签页图标\n- 社交媒体分享预览\n\n### 2.2 作者信息配置\n\n```typescript\nauthor: {\n  name: \"你的名字\",\n  email: \"你的邮箱\",\n  bio: \"个人简介\",\n}\n```\n\n作者信息会用于：\n- 首页展示\n- RSS 订阅源信息\n- 博客文章的作者信息\n\n### 2.3 社交媒体配置\n\n```typescript\nsocial: {\n  github: \"https://github.com/你的用户名\",\n  x: \"https://x.com/你的用户名\",\n  xiaohongshu: \"https://www.xiaohongshu.com/user/profile/你的ID\",\n  wechat: \"你的微信二维码图片链接\",\n  buyMeACoffee: \"https://www.buymeacoffee.com/你的用户名\",\n}\n```\n\n这些链接会显示在：\n- 首页的社交媒体链接区域\n- 导航栏的社交媒体图标\n\n### 2.4 评论系统配置\n\n```typescript\ngiscus: {\n  repo: \"你的GitHub仓库名\",\n  repoId: \"仓库ID\",\n  categoryId: \"分类ID\",\n}\n```\n\n使用 Giscus 作为评论系统，需要：\n1. 在 GitHub 上安装 Giscus 应用\n2. 在你的仓库中启用 Discussions\n3. 获取配置信息并填入这里\n\n### 2.5 导航菜单配置\n\n```typescript\nnavigation: {\n  main: [\n    { \n      title: \"文章\", \n      href: \"/blog\",\n    },\n    // 可以添加更多导航项\n  ],\n}\n```\n\n这里配置网站的导航菜单，支持：\n- 普通链接\n- 带子菜单的下拉菜单\n\n### 2.6 SEO 配置\n\n```typescript\nseo: {\n  metadataBase: new URL(\"https://你的域名.com\"),\n  alternates: {\n    canonical: './',\n  },\n  openGraph: {\n    type: \"website\" as const,\n    locale: \"zh_CN\",\n  },\n  twitter: {\n    card: \"summary_large_image\" as const,\n    creator: \"@你的推特用户名\",\n  },\n}\n```\n\n这些配置用于：\n- 搜索引擎优化\n- 社交媒体分享卡片\n- 网站元数据\n\n### 2.7 RSS 订阅配置\n\n```typescript\nrss: {\n  title: \"你的博客标题\",\n  description: \"博客描述\",\n  feedLinks: {\n    rss2: \"/rss.xml\",\n    json: \"/feed.json\",\n    atom: \"/atom.xml\",\n  },\n}\n```\n\n这些配置用于生成：\n- RSS 2.0 订阅源\n- JSON Feed\n- Atom 订阅源\n\n## 3. 如何修改配置\n\n1. 打开 `src/lib/config.ts` 文件\n2. 根据你的需求修改相应的配置项\n3. 保存文件后，Next.js 会自动重新构建并应用新的配置\n\n注意事项：\n- 确保所有 URL 都是有效的\n- 图片链接应该是可访问的\n- 社交媒体链接要填写完整的 URL\n- 配置修改后，建议检查网站的：\n  - 首页展示\n  - 导航菜单\n  - SEO 信息\n  - 社交媒体分享效果\n  - RSS 订阅源\n\n## 4. 如何生成 RSS 订阅源\n\n修改 scripts/generate-rss.js 文件中的配置，然后运行：\n\n```bash\nnpm run generate-rss\n```\n\n## 5. 如何生成 Sitemap\n\n修改 scripts/generate-sitemap.js 文件中的配置，然后运行：\n\n```bash\nnpm run generate-sitemap\n```",
    "title": "博客模板使用介绍",
    "date": "2022-04-05T21:10:00+08:00",
    "updated": "2022-04-05T21:10:00+08:00",
    "featured": true,
    "summary": "这是一个 Nextjs 博客模板，本文会介绍这个模板的一些基本用法",
    "keywords": [
      "hello",
      "world"
    ],
    "_meta": {
      "filePath": "intro.md",
      "fileName": "intro.md",
      "directory": ".",
      "extension": "md",
      "path": "intro"
    },
    "slug": "intro"
  }
]